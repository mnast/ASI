{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASI assessed exercise\n",
    "### *Naive Bayes Classifiera* and *Bayesian Linear Regression* for MNIST and CIFAR10 datasets\n",
    "7th June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">1</div> **Download the MNIST dataset and import it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import struct\n",
    "import pickle\n",
    "from time import time, strftime\n",
    "from numpy.linalg import pinv,inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters of the MNIST dataset\n",
    "num_classes = 10\n",
    "img_size = 28\n",
    "num_images = 60000\n",
    "num_test_images = 10000\n",
    "\n",
    "# file paths\n",
    "fname_img = r'D:\\ASI\\MNIST\\train-images.idx3-ubyte'\n",
    "fname_lbl = r'D:\\ASI\\MNIST\\train-labels.idx1-ubyte'\n",
    "fname_img_test = r'D:\\ASI\\MNIST\\t10k-images.idx3-ubyte'\n",
    "fname_lbl_test = r'D:\\ASI\\MNIST\\t10k-labels.idx1-ubyte'\n",
    "\n",
    "# load data (input two files: data and labels)\n",
    "def load_data(filename1, filename2):\n",
    "    with open(filename1, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "    with open(filename2, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows * cols)\n",
    "    return img, lbl\n",
    "\n",
    "# show given image\n",
    "def show_image(image):\n",
    "    image = image.reshape((img_size,img_size))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=plt.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (60000, 784)\n",
      "(10000,) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# load the MNIST train and test datasets\n",
    "img, lbl = load_data(fname_lbl, fname_img)\n",
    "img_test, lbl_test = load_data(fname_lbl_test, fname_img_test)\n",
    "\n",
    "print(lbl.shape, img.shape)\n",
    "print(lbl_test.shape, img_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">2</div> **Comment on the distribution of class labels and the dimentionality of the input and how these may affect the analyses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the prior distribution of classes\n",
    "def compute_prior(lbl):\n",
    "    prior = []\n",
    "    for i in range(num_classes):\n",
    "        prior.append(sum([1 for x in lbl if x == i])/num_images)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2da3d42c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior = compute_prior(lbl)\n",
    "\n",
    "# plot histogram\n",
    "plt.hist(lbl, bins=10, normed=True, color='salmon')\n",
    "plt.title('Histogram MNIST dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The dimensionality of input is 28 x 28 = 784. Data is 784-dimensional vector of values from 0 to 255, so we will use the Gaussian likelihood.  \n",
    "We can assume that the distribution of classes is uniform. Thereby, the prior almost will not have any affect to the analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">3</div> **Classification**  \n",
    "\n",
    "**a) Implement the  `Naive Bayes classifier` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the mean and std of each pixel for each class\n",
    "def compute_mean_and_std(img):\n",
    "    mean = []\n",
    "    std = []\n",
    "    # compute mean and std for each class\n",
    "    for k in range(num_classes):\n",
    "        # chose images that belongs to class k\n",
    "        indices = np.argwhere(lbl == k)[:,0]\n",
    "        img_ = img[indices,:]\n",
    "        mean.append(np.mean(img_, axis=0))\n",
    "        std.append(np.std(img_, axis=0))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# compute Gaussian loglikelihood for given image and class\n",
    "def compute_log_likelihood(image, k):\n",
    "    # take into account only pixel that have std not equal = 0\n",
    "    indices = np.argwhere(std[k] != 0)[:,0]\n",
    "    std_im = std[k][indices]\n",
    "    mean_im = mean[k][indices]\n",
    "    image = image[indices]\n",
    "    # compute loglikelihood\n",
    "    llh = (- np.log(std_im) - np.log(np.sqrt(2*math.pi)) - ((image-mean_im)**2/(2*std_im**2))).sum()\n",
    "    return llh\n",
    "\n",
    "\n",
    "# make predictons, compute the accuracy\n",
    "def predict(images, labels):\n",
    "    # count correct predictions\n",
    "    count = 0\n",
    "    N = len(images)\n",
    "    predictions = np.array([],int)\n",
    "    for i in range(N):\n",
    "        # compute posterior for all images for each class\n",
    "        posterior = [compute_log_likelihood(images[i,:], k) * prior[k] for k in range(num_classes)]\n",
    "        # make prediction (take the max posterior between 10 classes)\n",
    "        pred = posterior.index(max(posterior))\n",
    "        predictions = np.append(predictions, pred)\n",
    "        # count correct predictions\n",
    "        if pred == labels[i]:\n",
    "            count += 1\n",
    "    accuracy = count/N\n",
    "    return predictions, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test takes 0.148021 minutes\n",
      "The accuracy =  0.5807\n"
     ]
    }
   ],
   "source": [
    "# test classifier and get the accuracy\n",
    "mean, std = compute_mean_and_std(img)\n",
    "\n",
    "t0 = time()\n",
    "predictions, accuracy = predict(img_test,lbl_test)\n",
    "t1 = time()\n",
    "\n",
    "print('The test takes %f minutes' %((t1-t0)/60)) \n",
    "print('The accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.5807\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**—Å) Describe any data pre-processing that you suggest for this data and your classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The MNIST dataset provides greyscale images. We will convert greyscale images to black and white, so all pixel have 0 or 1 value and will calculate the likelihood based on the frequency of occurrence of each pixel (Bernoulli likelihood).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Apply your classifier to the dataset. Make sure your optimization is clearly commented. Use classification accuracy and test log-likelihood as your figures of merit.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert grayscale image to black and white\n",
    "def convert_images(img_grayscale):\n",
    "    img_black_white = np.zeros((len(img_grayscale),img_size*img_size))\n",
    "    # find non-zero values in grayscale image\n",
    "    ind = np.nonzero(img_grayscale)\n",
    "    # put all non-zero values to 1\n",
    "    for i in range(len(ind[0])):\n",
    "        a = ind[0][i]\n",
    "        b = ind[1][i]\n",
    "        img_black_white[a][b] = 1\n",
    "    return img_black_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2da3d44d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGjL4UkMGX2rI4EsNGXypof8DnBhYZ9iwCrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2da3d44d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_bw = convert_images(img)\n",
    "\n",
    "# show random image before and after conversion\n",
    "x = np.random.random_integers(0, high=num_images)\n",
    "show_image(img[x,:])\n",
    "show_image(img_bw[x,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute mean for black and white images\n",
    "mean,_ = compute_mean_and_std(img_bw)\n",
    "# convert test images \n",
    "img_bw_test = convert_images(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rewrite the function that compute likelihood for given image and class\n",
    "# likelihood of each pixel(0/1) is frequency of occurrence of this pixel\n",
    "def compute_log_likelihood_2(image, k):\n",
    "    llh = (np.log(mean[k]*image+(1-mean[k])*(np.logical_not(image).astype(int)))).sum()\n",
    "    return llh\n",
    "\n",
    "# make prediction, compute and plot accuracy\n",
    "def predict_2(images, labels):\n",
    "    # count correct predictions\n",
    "    count = 0\n",
    "    N = len(images)\n",
    "    predictions = np.array([],int)\n",
    "    for i in range(N):\n",
    "        # compute posterior for all images for each class\n",
    "        posterior = [compute_log_likelihood_2(images[i,:], k) * prior[k] for k in range(num_classes)]\n",
    "        # make prediction (take the max posterior between 10 classes)\n",
    "        pred = posterior.index(max(posterior))\n",
    "        predictions = np.append(predictions, pred)\n",
    "        # count correct predictions\n",
    "        if pred == labels[i]:\n",
    "            count += 1\n",
    "    accuracy = count/N\n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test takes 0.080968 minutes\n",
      "The accuracy =  0.8268\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "t0 = time()\n",
    "predictions, accuracy = predict_2(img_bw_test,lbl_test)\n",
    "t1 = time()\n",
    "\n",
    "print('The test takes %f minutes' %((t1-t0)/60)) \n",
    "print('The accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.8268\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Display the confusion matrix on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "     0     1    2    3    4    5    6    7    8    9\n",
      "0  848     0   18   11    2   11   15    2   11    9\n",
      "1    0  1038    5    5    1    1    5   16    5    7\n",
      "2    2    14  846   34    4    2   14   17   10    4\n",
      "3    1     2   12  701    1   31    0    1   22    4\n",
      "4    1     1   18    4  798   11   12   25   12   80\n",
      "5  110    44   34  173   36  810   72   14  144   32\n",
      "6   11     5   29    7   17   13  839    0    5    0\n",
      "7    1     0   10    9    2    0    0  811    4    9\n",
      "8    6    31   58   48   15    4    1   35  734   21\n",
      "9    0     0    2   18  106    9    0  107   27  843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(predictions, lbl_test)\n",
    "\n",
    "# display confusion matrix: actual values are presented by rows, predicted by columns\n",
    "print('Confusion matrix:\\n')\n",
    "print(pd.DataFrame(conf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Discuss the performance, compare them against a classifier that outputs random class labels and suggest in which performance could be improved.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "- `Naive Bayes classifier` is easy and fast to implement, it performs well and doesn't need a lot of train data.  \n",
    "- We observed that its performance is better with categorical features (Bernoulli likelihood) than with continuous (Gaussian likelihood). This is due to the fact that the normal distribution is a very strong assumption.  \n",
    "- For `Naive Bayes classifier` we assumed that the values of features are independent, that's not quite right, but `Naive Bayes classifier` performs well enough. We can suggest multivariate normal distribution and apply the `Bayes classifier`.  \n",
    "- A classifier that outputs random class labels will provide the accuracy about 0.10, and we obtained 0.83.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">4</div> **Linear Regression**\n",
    "\n",
    "**a) Implement `Bayesian linear regression`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add bias to train dataset\n",
    "X = np.append(img,np.ones((num_images,1)),axis=1)\n",
    "t = lbl\n",
    "\n",
    "# compute w_hat and sigma2_hat (by maximizing likelihood)\n",
    "w_hat = np.dot(np.dot(pinv(np.dot(X.T,X)),X.T),t)\n",
    "sigma2_hat = np.dot((t - np.dot(X,w_hat)).T,(t - np.dot(X,w_hat)))/num_images\n",
    "\n",
    "# add bias to test dataset\n",
    "X_new = np.append(img_test,np.ones((num_test_images,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean of the prior\n",
    "O = np.zeros((img_size*img_size+1,1)); \n",
    "# covariance of the prior\n",
    "S = 10 * np.identity(img_size*img_size+1) \n",
    "\n",
    "# covariance of the posterior\n",
    "SIGMA = inv(1/sigma2_hat*np.dot(X.T,X) + inv(S))\n",
    "# mean of the posterior\n",
    "MU = 1/sigma2_hat*np.dot(np.dot(SIGMA,X.T),t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Treat class labels as continuous and apply regression to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions as continuous variables and plot the prediction versus the true targets \n",
    "def predict_continuous(X_new, t_new, w):\n",
    "    predictions = []\n",
    "    N = len(X_new)\n",
    "    \n",
    "    # plot settings\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.xlabel('Image number')\n",
    "    plt.ylabel('True and predicted values')\n",
    "    plt.grid(True)\n",
    "    plt.xlim((0,N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        # predict the value\n",
    "        pred = np.dot(X_new[i,:], w)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "        # plot the prediction versus the true targets \n",
    "        plt.scatter(i, pred, color='fuchsia', alpha=0.7,s=1)\n",
    "        plt.scatter(i, lbl_test[i], color='limegreen', alpha=0.7,s=1)\n",
    "\n",
    "    plt.show()\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Produce a scatter plot showing the prediction versus the true targets for the test set and compute the mean squared error on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the predictions with MU as the value of model parameters\n",
    "predictions = predict_continuous(X_new,lbl_test,MU)\n",
    "\n",
    "error = predictions - lbl_test\n",
    "print('mean of error:',np.mean(error),'\\nstd of error:',np.std(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the test set: 3.151\n"
     ]
    }
   ],
   "source": [
    "# compute MSE\n",
    "def compute_mse(predictions, targets):\n",
    "    MSE = ((predictions - targets)**2).sum()/num_test_images\n",
    "    return MSE\n",
    "\n",
    "MSE = compute_mse(predictions, lbl_test)\n",
    "print('MSE on the test set:',round(MSE,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Suggest a way to discretize predictions and display the confusion matrix on the test data and report accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "To discretize predictions we can round obtained values up to integers. It will be more correct mathematically, but if we take only integer part of predictions, we will obtain accuracy slightly bigger (the difference is 4%).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_discrete(X_new, t_new, w):\n",
    "    N = len(X_new)\n",
    "    count = 0\n",
    "    #predictions = []\n",
    "    predictions = np.array([],int)\n",
    "    for i in range(N):\n",
    "        # discretize predictions by mathematical rounding of prediction\n",
    "        pred = int(round(np.dot(X_new[i,:], w),0))\n",
    "        # discretize predictions by taking integer part of prediction\n",
    "        #pred = int(np.dot(X_new[i,:], w))\n",
    "        #predictions.append(pred)\n",
    "        predictions = np.append(predictions, pred)\n",
    "        # count correct predictions\n",
    "        if pred == t_new[i]:\n",
    "            count += 1\n",
    "    accuracy = count/N\n",
    "    return predictions, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy = 0.2208\n"
     ]
    }
   ],
   "source": [
    "# get the results with MU as the value of model parameters\n",
    "predictions, accuracy = predict_discrete(X_new,lbl_test, MU)\n",
    "print('The accuracy =',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.2208 (0.2599)  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  50   0   4   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 173   1  31   7   0   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0 328 229 123  43   0   3   4   1   1   1   0   0   0   0]\n",
      " [  0   0   0 257 570 244 196   5  21  24   6  10   4   0   0   0   0]\n",
      " [  0   0   0 103 222 304 325  36 118  73  26  27   9   0   0   0   0]\n",
      " [  0   0   0  36  88 217 273 197 253 158  74 100  25   0   0   0   0]\n",
      " [  0   0   0  22  18  84 100 338 288 265 141 189  58   0   0   0   0]\n",
      " [  0   0   0   8   6  18  42 249 143 270 241 277 142   0   0   0   0]\n",
      " [  0   0   0   2   1   1  12 115  36 117 283 229 312   0   0   0   0]\n",
      " [  0   0   0   0   0   3   9  39  19  43 159 103 319   0   0   0   0]\n",
      " [  0   0   0   0   0   0   3   3   5   2  70  29  96   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4   0  19   8  36   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   6   1   5   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(predictions, lbl_test)\n",
    "\n",
    "# display confusion matrix: actual values are presented by rows, predicted by columns\n",
    "print('Confusion matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy = 0.2205\n"
     ]
    }
   ],
   "source": [
    "# sample from the posterior distribution of the parameters of the model and compute expectation of w\n",
    "num_samples = 100000\n",
    "samples = np.random.multivariate_normal(mean=MU,cov=SIGMA,size=num_samples)\n",
    "expected_w = np.mean(samples, axis=0)\n",
    "\n",
    "# make predictions and compute the accuracy with expected value of w\n",
    "predictions, accuracy = predict_discrete(X_new,lbl_test,expected_w)\n",
    "print('The accuracy =',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.2205\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The average of parameters of model tends to mean of this model (MU), if we produce more samples the accuracy will be closer to the accuracy obtained with MU (0.2208).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Discuss regression performance with respect to classification performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The performance of Linear regression is low, because regression is not the best fit for classification problems. For regression the output variable takes continuous values, for classification the output variable takes class labels. Output variable can be a discrete value like in our case, but these class labels don't have any order. We can change the order of our labels and we will obtain a different result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Describe one limitation of using regression for this particular task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Regression and classification are both related to prediction, where regression predicts a value from a continuous set, whereas classification predicts the 'belonging' to the class. We can use regresion for classification task where the output variable is ordinal. For example if we want to predict the price where the price is categorical like: 'very expensive', 'expensive', 'affordable', 'cheap', and 'very cheap'.  \n",
    "For this particular task we shold use `Bayesian Logistic regression`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">1</div> **Download the CIFAR10 dataset and import it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'D:\\ASI\\CIFAR10\\cifar-10-batches-py'\n",
    "filename = [path + '\\data_batch_' + str(x) for x in list(range(1, 6))]\n",
    "filename_test = r'D:\\ASI\\CIFAR10\\cifar-10-batches-py\\test_batch'\n",
    "\n",
    "num_classes = 10\n",
    "num_channels = 3\n",
    "img_size = 32\n",
    "num_images_per_file = 10000\n",
    "num_images = 5 * num_images_per_file\n",
    "num_images_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unpickle data from file\n",
    "def unpickle(file):\n",
    "    with open(file, mode='rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "# convert and reshape the raw data \n",
    "def convert_images(raw):\n",
    "    # convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "    # reshape the array to 4-dimensions\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "    # reorder the indices of the array\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "    return images\n",
    "\n",
    "# load data from file\n",
    "def load_data(filename):\n",
    "    data = unpickle(filename)\n",
    "    raw_img = data[b'data']\n",
    "    lbl = np.array(data[b'labels'])\n",
    "    img = convert_images(raw_img)\n",
    "    return img, lbl\n",
    "\n",
    "# load all train data (from 5 files)\n",
    "def load_training_data(filename):\n",
    "    img,lbl = load_data(filename[0])\n",
    "    for i in range(4):\n",
    "        img_,lbl_ = load_data(filename[i+1])\n",
    "        tmp_img = np.append(img, img_, axis=0)\n",
    "        tmp_lbl = np.append(lbl, lbl_, axis=0)\n",
    "        img = tmp_img\n",
    "        lbl = tmp_lbl\n",
    "    return img, lbl\n",
    "\n",
    "# show given image\n",
    "def show(image):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=plt.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n",
      "(10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# loading the training data\n",
    "img, lbl = load_training_data(filename)\n",
    "# loading the test data\n",
    "img_test, lbl_test = load_data(filename_test)\n",
    "\n",
    "print(img.shape, lbl.shape)\n",
    "print(img_test.shape, lbl_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHZhJREFUeJztnWmMXNd5pt+v9qpu9kb2wn3TSCJpRZRnoiBhJqMktkcY\nDCDHmTEMBwPbAYL8iBMD/hHZmR/6G3sADYwA/uMNtBFjJjHgSMF4bEo2PAPLI4WxxFWkdm4Su7n0\n3l1d2z350UWyTdf7scnurmrNeR+AYPX96t5z7rn3q1t13/t+x0IIEELERarTHRBCtB8lvhARosQX\nIkKU+EJEiBJfiAhR4gsRIW1LfDN73MzOmtnrZvZku9olfTlnZsfN7BUz+6c2t/0NMxszsxNLlvWb\n2REze83MfmRmvR3sy1NmdsnMXm7+e7wN/dhmZj8xs9NmdtLM/qK5vO3j0qIvf95c3olxyZvZS83z\n9KSZPdVcvvJxCSGs+T8sfsC8CWAngCyAYwAebEfbpD9vA+jvUNu/DeAggBNLln0JwF82Xz8J4K87\n2JenAHy+zWMyAuBg83U3gNcAPNiJcXH60vZxafah1Pw/DeBFAI+uxri064r/KIA3QgjnQwg1AP8D\nwBNtarsVhg79zAkh/AzAxG2LnwBwuPn6MICPdrAvwOL4tI0QwmgI4Vjz9SyAMwC2oQPjQvqytRlu\n67g0+zDffJkHkAEQsArj0q6TfyuAi0v+voRbg9kJAoDnzOyomf1JB/txg6EQwhiweOIBGOpwfz5r\nZsfM7Ovt+tlxAzPbhcVvIS8CGO7kuCzpy0vNRW0fFzNLmdkrAEYBPBdCOIpVGJdYb+4dCiF8EMB/\nAPBnZvbbne7QbXTyOeqvAtgTQjiIxZPt6XY1bGbdAL4H4HPNq+3t49C2cWnRl46MSwghCSE8gsVv\nQI+a2QGswri0K/HfBbBjyd/bmss6QgjhcvP/qwC+j8WfIp1kzMyGAcDMRgBc6VRHQghXQ/PHI4Cv\nAfj1drRrZhksJtp3QgjPNBd3ZFxa9aVT43KDEMI0gJ8CeByrMC7tSvyjAO4zs51mlgPwCQDPtqnt\nX8LMSs1Pc5hZF4CPADjV7m7gl38vPgvg083XnwLwzO0rtKsvzRPpBh9D+8bmmwBeDSF8ZcmyTo3L\nr/SlE+NiZptu/KQwsyKAD2PxnsPKx6WNdycfx+Id0jcAfKHdd0eX9GM3FlWFVwCcbHdfAHwXwHsA\nKgAuAPgMgH4AzzfH5wiAvg725dsATjTH6B+w+HtyrftxCEBjyXF5uXm+DLR7XJy+dGJcHmq2f6zZ\n9n9tLl/xuFhzQ0KIiIj15p4QUaPEFyJClPhCRIgSX4gIWVHiryfjjRBi+dzzXX0zSwF4HcDvY1ES\nOgrgEyGEs7e9T7KBEB0ihNDSX5BZwTZvGm8AwMxuGG/O3v7GD/3BYwCAt868g737di/pVEI3niT8\n8yKXztFYMVegsUI2ffP1yeNn8dDDD978Ox0adD3jIZjzpSmd5/2sL1nt+Cuv4uFH9t/8u1Kr0/Vy\nGX7Ikuo0jTUafCfqSf7m61dPv4H9B/7VrfUSfoyqaecY8V1A4mzzcvnWPrz75iVsvW/b0o7S9TaV\n+mismC/S2K49e2ns0nu3Hi49ffw0Djx84Obf5blZul4mxcclZfx8sTQ/tlYv3+rLq2/hwP5b/a6W\n51qu8+wPfs77QSN3Zr0Zb4QQy2QlV/xl89aZdwAAE1cnMb5pAgOD/e1oVghBWEniL9t4c+Pr/XpK\n+qHhTZ3uwk2GRwY73YWbDA4OdLoLN9kw0NPpLtxkcHg9HaOV59BKvurftfFmvSQ9AAyPrJ/EH9m8\njk6qoY2d7sJNetZR4g+NdLpEwi2GVuHD+Z6v+CGEhpl9FosmgRSAb4QQzrR6L7vXkU5n6fbTS27E\n3U4+x9fLZfkNNaR4AZU6eHv1SpVvs87vYqVq/CZPw7FQO/c1YY4Kk1R5P72bpfXAP/8b/H4aEme9\nxLkhulDlN8bm5/kNymK2i8YaToPl8gKNTUy0KkC0SL1Wo7GaE2vA2XkHS/F0TNX5PiT1u29vRb/x\nQwg/BPDASrYhhGg/enJPiAhR4gsRIUp8ISJEiS9EhCjxhYiQtjy5l/ckNkLKuPTWqHMppeI8cw/j\nkl2S8PZCw3v2mjfXcKQ+c/Yv5Xwe1x3ZquHKOo606Dw7Xwt8zCrBOX1ae0MAAGXn+FUbPFbkKq7r\nRfDmwUil+Fh7Bra6c2zTjpzneeKC42fLJLy9jLMPDF3xhYgQJb4QEaLEFyJClPhCRIgSX4gIUeIL\nESFtkfNqC5WWy30JxiHjaGiOXJJ33E85xymYy3E5MgGXWRJH8vFKaFnascSBx/o3c6vx3Dx3d12+\n2rp0EwBMBV7KzHK8pFU6aX3MAaDmSH1eWa7EOV+8yo7pDL++ZRynZ+Job57UZ2neXso5QT1VLqne\nm5uT90MIER1KfCEiRIkvRIQo8YWIECW+EBGixBciQtoi55XnW8tFniSS8WaMcdYr5fh6Q70lGhvc\nyCu65vPOMDmFOEtp7mzLOsVEzXGh9Q9soLGh4R00dvHd6zT2z6fO0dj1aT4uxawjy01fpbG0M4NS\nypmBJ19yZDJHz0scx+Z8eZ7GLM33L+McP0c9RD7rzKRT5xLoXOCuxZC6B/frXa8hhHjfo8QXIkKU\n+EJEiBJfiAhR4gsRIUp8ISJkRXKemZ0DMIVFy1gthPBoq/exwoRewUmvmGFXhsszu4e6aWy4l7vJ\nQuCyzoU33qGxPSObaaynyNubHp+ksZHtW2ls2yY+eePUDHfZTU/wOem6C9yB1zvF1wvEdQkA9XqZ\nxipOUVDHnIe845LMOvJvcOZFzDqSq2cC9SQ7rwBrcByGC0T2BoDgWPAajkOUsVIdPwHwWAiBzzwo\nhFh3rPSrvq3CNoQQbWalSRsAPGdmR83sT1ajQ0KItWelX/UPhRAum9kgFj8AzoQQfnb7my6cu3zz\ndW9fN3r7+GOnQoi1Z0WJH0K43Pz/qpl9H8CjAH4l8Xfs4jfAhBDt556/6ptZycy6m6+7AHwEwKnV\n6pgQYu1YyRV/GMD3zSw0t/O3IYQjrd7IXHieO88rxFnq7qKxhXEuMR1//QyNzS9wOS+T55+PD+7t\npbGas3/Xpnh7xX5eGLNrfIrGTpx5m8aOneWSZM2cgprOfINI8f3zXG+zNX5s0yneXj7DbYsZZ72c\nUxS0u8RjM5Pc0Zg48/81Glxem6vwcamWZ2ksm+PHKDGvOGtr7jnxQwjvADh4r+sLITqHpDghIkSJ\nL0SEKPGFiBAlvhARosQXIkLaUmwzRexKjtrluvPGrnJP0LvTMzRWKXOpzxzn1/0POA68Xi7nWY3v\nw4Yevt6G3j4am1/gUl8qz/eh0NdPY2OXeWFMc45DxnH1zTrOvaoz/19fN3+qs5DL01gu4adyvcql\nt7kZfr4sOPLa3Cx3LVriOfB4e7msl47c8he8CSMJuuILESFKfCEiRIkvRIQo8YWIECW+EBGixBci\nQtoi5+XyrWWYqjPvXNopglh15JkKuJSSLfFtFhwHXghcSvmnl1+jsd86uI/GHrz/fhobm+RS0Ysn\nzvJt7uPbHBrmEtoFp/BndxcvXmqOWy7nXFNqZV6Ic0OBtzc3y+W163Pc9Vap8nMi18XdefNlfp5V\nHbkyafBYcGS5TIb3JUkcOc/TxQm64gsRIUp8ISJEiS9EhCjxhYgQJb4QEaLEFyJC2uTOa/354s2d\nx9YBgLpTALK4oYfGsgmXWbqzrlWQhi44TsGD+/l6+/ffR2Nnf/oCjZ278B6NbdvC59VLO7s30L+R\nxgpp7virOUUlkyleFBQVLq9NjPICl9WqM7dc4NJbqcTPiVSKp4BjskNS41J0SHhfMnku2Tk1SNFw\nzsFajbfH0BVfiAhR4gsRIUp8ISJEiS9EhCjxhYiQOya+mX3DzMbM7MSSZf1mdsTMXjOzH5kZLyAn\nhFh3LEfO+xaAvwHw7SXLvgDg+RDCl83sSQBfbC5rSdJo7QzzJDtv7jxvpjDvk6ynjxexHBngRR4P\nPMClN8fUh+4Sd69dm+Cy1c7twzT2X/7wMRrL5Us0dvQkn1evscBHdDpwCe3qdV6kc/w6lzkzDS7j\nVhPeXsqRXAsFfioHcv4BQNkpmllf4G7AhjPXYqHAi4J6J2+lyuVmr/hsNsvPM8Ydr/jN+e5vP4pP\nADjcfH0YwEfvumUhRMe419/4QyGEMQAIIYwC4E+OCCHWHat1c+/uKwEIITrGvT6yO2ZmwyGEMTMb\nAXDFe/Pbb166+bp/oAf9A/wRSiHE2rPcxDf88lQezwL4NIAvAfgUgGe8lffct+1e+iaEWCOWI+d9\nF8DPAdxvZhfM7DMA/hrAh83sNQC/3/xbCPE+4Y5X/BDCJ0noQ8tthMl291IkEADSzhxj5hQzLDiF\nFXft3U1jGzfyeecqZS4/nX6bO+ka4FJYV4HLMzu3ckkyl++isStXeHsXl/wUu52FOpdV5xz5KeUU\n4kwl3F1pTmHTbIqv513B6k5RV6+AZ9kpCtpwil+Wy1x6qzqOxnKFz4uYJwVrAWBwcJDGGHpyT4gI\nUeILESFKfCEiRIkvRIQo8YWIECW+EBHS0WKbnpyXyfCupVNcSkmn+DbTWV440hynYEhxaeriNS75\nHHuHz0k3do3LSIP93CmY6+YO6JRxp1nVKQ553w4uBzUSZ9+vcIfhtZkZvk3jx6iY5bJVxrlMJTXP\nvcaPe84pfjlb4ducn+buvOC4D5Hm42ng7XlO1tHRUd4e295dryGEeN+jxBciQpT4QkSIEl+ICFHi\nCxEhSnwhIqQtcl5CCvR4EkUhx2WdulOIs7ubO9SGhnkRy+AMxVSZt3d+jMtys3O8suLY2DiNJQmX\nu86N8vY25rkcdP+OzTS2aZjHevq4fHhtnMuVvzh+lsbePsfdgLUKH7PEKQparXOn4EKay2vT81yO\nrVS5W86bry6X4/KhVzC0VOQybqFQ4O05ciXtx12vIYR436PEFyJClPhCRIgSX4gIUeILESFKfCEi\npC1yXiAFMB0PE5KESzc1x4m1a8dOGhty6vlX5qZorFrnfanUuIw0PckLXObT3C03P8PXK89vp7GB\nTQM0VuzhrrDCBi4jDY5sorE9O3nZ9AP7HqCx4ydepbH/9cP/Q2OT17njz9K8ECdS/DQvlbj8O9DP\nC5tW0vyamc/zsc4WufTW3cWl07wj59G5+o7ycdYVX4gIUeILESFKfCEiRIkvRIQo8YWIkOXMnfcN\nMxszsxNLlj1lZpfM7OXmv8fXtptCiNVkOXLetwD8DYBv37b86RDC08tppFptLb+lHUHPm++s1NNN\nY/v2309jjTlejHJslktFU9M81tdborH79nLp7dp1PrN4v1Ns84MP76OxoS5nbrkaLw7ZVeL70N3F\n5a58kUtMPX381BrZ/BiNbdmxg8Z+8uP/S2Nvv3WexpDnMm5XF9/3mWm+f6V+Pta5HN/3bJG7TguO\ntOjJjiXn+DHueMUPIfwMwESLkCfDCyHWMSv5jf9ZMztmZl83M/7kgRBi3XGvif9VAHtCCAcBjAJY\n1ld+IcT64J4e2Q0hLH2m9GsA/tF7//m3blVc6e3vQZ/z6KwQYu1ZbuIblvymN7OREMKN6Ts+BuCU\nt/LOvfyZbiFE+7lj4pvZdwE8BmCjmV0A8BSA3zWzgwASAOcA/Oka9lEIscrcMfFDCJ9ssfhbd9MI\nk/Mqc7zQ4eR4KyFhkd/4nd+ksd4+LoVNzfICl7kcl26my9yBl3Zuk2wZHqKxwU38506xxN1dGebE\nAlAa4O68dG2Or5d3nG0ZLt4EZ37DbIHLT+kcn6/uNw/xMRse5k7BH/zgxzR2/jKXcQuOJNnf309j\n6QZ3iBYcOS/Xzfe90MXPXU+y85x7DD25J0SEKPGFiBAlvhARosQXIkKU+EJEiBJfiAhpS7HNi+ff\na7l8znG91at8brKBgY00Viw484g5rr7r43xOuiThn4+ZNJdZZmf5NtMZvk2vmOjCAnctmiOhJcbn\nbMs68mGScoqeOnMf1vnhQz7Dj1Ehz2Pbto/Q2L9+5AM0Nlfhz5dlnXn1ikUuveVTfL18lqdVVx8/\nB7t6uXwIW11PnK74QkSIEl+ICFHiCxEhSnwhIkSJL0SEKPGFiJC2yHnT14msFXjzIXD5aX6Gy4C5\nLHevFTcN0tjkFHdwzcxzp2C6xB1VhW4eS2e4I66ywPevx3HSpdDg20z4eNYb/PM/60hvMC4D1mq8\nL9XAXZkVZ245NgcjAGwf4lLYow/dR2Oj01wevbDAHY0pZ+684Mic1Sofl4ZzXufz/Lzu7uYSIUNX\nfCEiRIkvRIQo8YWIECW+EBGixBciQpT4QkRIW+S8lLX+fAme4ajBZQ8Dd4whcWSkKpduQPoIAHlH\nQnMULRRKvKBmNeHb7O/nRSU3beSOsXqFy2Tz83zuvO6iMz+eUxgzleI7Pz5+ncZmpnls0DlGPd38\nGBUdSStf5A7Knjo/DnnwvtTqvC8zFX5imyPn7ezro7GU4wa8doXPw0i3d9drCCHe9yjxhYgQJb4Q\nEaLEFyJClPhCRMgdE9/MtpnZT8zstJmdNLO/aC7vN7MjZvaamf3IzHrXvrtCiNVgOXJeHcDnQwjH\nzKwbwC/M7AiAzwB4PoTwZTN7EsAXAXzhbhpPAq/I2NPLZaR9D+ylMc+hNnrtKo1V69y9lslyySfr\nmNdKJe6osjqXwoZGNtPY8BBvcGJijMbqjjxaTvhpUEzzedkyjgR68RLvy6VzrYuvAsDWCe6S3LuX\njwuTjAHgzJvnaGxDN79effDXDtBYzUmd85e5XDlX4RJhqPNjlDhyXs3ZJuOOV/wQwmgI4Vjz9SyA\nMwC2AXgCwOHm2w4D+Ohdty6E6Ah39RvfzHYBOAjgRQDDIYQxYPHDAQCf5lQIsa5YduI3v+Z/D8Dn\nmlf+278b8+/KQoh1xbIe2TWzDBaT/jshhGeai8fMbDiEMGZmIwDoc4MLlYVbDaYzyDjzqgsh1p7l\nXvG/CeDVEMJXlix7FsCnm68/BeCZ21e6QSFfuPlPSS9E57ljFprZIQB/BOCkmb2Cxa/0fwXgSwD+\nzsz+GMB5AB9fy44KIVaPOyZ+COEFAEzP+tCyWiFKRGjwOeKGHUlr965tNNaocWmjXObutdEr4zRW\ncNxd1YUKjyV8m33DO2gsnedfxLo28AKeISzQ2PUZ7s6bc+a5y1a4xJRx5NgzZ9+ksX9+4Rc0NtDP\n5bWtu7hr8YO/cZBvc5ifSxNXeSHVrh7ulit1cTeg54R87f+doLEreS6d7t69h8a2OrnC0JN7QkSI\nEl+ICFHiCxEhSnwhIkSJL0SEKPGFiJD2PE1jrSWhVJo/5bt7J5fssk5BzalxPv/YNcf5derUKRrL\n57gjrljgEkziONv2OIUqC0XuxJrnu4d8hq+Xdp6oLs+TuQ0BNGo8Njc5SWPnz52nsQsXLzgx3s+Z\nBS6B9m7cSGO7dz9AY+UyL9x6/PWLNDY8xOdhzHXxIqtTzvx4V9/kY/bm6+dobMeO7TTG0BVfiAhR\n4gsRIUp8ISJEiS9EhCjxhYgQJb4QEdJROW/bZi7BHHpkP43lq9z9NF/hbrnxiSkau3DxXRqrOG6r\nUhd37nX1cMlneCuXK6v9XAa0Cj9keUda7Mlz+fBdR3qbmuby09hlXlBzZo7LgFt376KxJOGOzXSO\nj/W5t3kBz8lxfvxmK1zO2zC0hcYyjqUx7WTVv/v3/5HGUnzXUXbOwSyp+Hrkxy/wtnhTQoj/X1Hi\nCxEhSnwhIkSJL0SEKPGFiBAlvhAR0hY5r5BvXavzgd1b6Tob0lyWu/7uWzRWNT7P3aV3eAHI8Wle\niLOU54UVQ4M74q5dvkxjb53iRRcf3vMRGkOFy2Qz89wtt3MzL8h47PRZGjt1lo91Xz+fPGnfwX9D\nY6USLxg64zj+PIdhLs/nKazVuPS2ebCLxroHBmjMnLnsenr4/g0NOq4+xwVacPaPVrP9b/+drqEr\nvhARosQXIkKU+EJEiBJfiAhR4gsRIXdMfDPbZmY/MbPTZnbSzP68ufwpM7tkZi83/z2+9t0VQqwG\ny5Hz6gA+H0I4ZmbdAH5hZs81Y0+HEJ6+0wa6N7SWTGadypGjY6M01lfi0sbwFu6o2rWFy08vn3iH\nxsYneD/rjsqycyuXgw7s5rJOMnONxq4Zd9n19HIZaWqSz+Nn4A61wUEuA+aLfJ47T9Lq6+unsYGN\nfL66wU3czVkqcedeKsWvb5k8l9DqgY9LEri06KyGRoMHFxxnaa3BC8xms/ycYCxn0sxRAKPN17Nm\ndgbADQGei5lCiHXLXf3GN7NdAA4CeKm56LNmdszMvm5m/ONfCLGuWHbiN7/mfw/A50IIswC+CmBP\nCOEgFr8R0K/849dnb/4rz/NprIUQ7WFZj+yaWQaLSf+dEMIzABBCuLrkLV8D8I9s/YGN/JFXIUT7\nWe4V/5sAXg0hfOXGAjMbWRL/GAA+FY0QYl1xxyu+mR0C8EcATprZKwACgL8C8EkzOwggAXAOwJ+u\nYT+FEKvIcu7qvwCgleXth8ttpLev9X2/yfkFus75a3yeu94H99LYlh18frVDJf6TY/Qqd+e9+PIZ\nGtu+hctPH/+D36OxD9zHi22OvctdfbUGl5EmZ5wipJNcKtq4aZjGshu4VNRIuKiTyXCXZKnIt5kf\n4Meo0MWLiXrteUVIgyfZ1Xks1TIlmus5jk0E/iXbHPdhJsXbS9+DuKYn94SIECW+EBGixBciQpT4\nQkSIEl+ICFHiCxEhbSm2ObCxtUttdoZLdm9d5kUXt+zibTVSfJdKBe7E2vfAThrL5vg2D/36B2js\n/vt5MVFvmwuOVDQxMUdjswv8cejJMp+YrX94O4319PfQWHc3j2WcCeQ8t1zDuDRlGb4emz8OAGp1\n7mzzXHYI/Dh4/jRz9iFf4FJm0ZEdG447b2GBS7UMXfGFiBAlvhARosQXIkKU+EJEiBJfiAhR4gsR\nIW2R8w58oLXkNTPNi1hOTHA5r5rwz6uQ5tUvZ8p8DrVqwp1YH//Ex2msJ8fXK1e59Hb9Op8D76VT\nfI6/nj5epHPz9j001pvnxSizBT5/nKW5NFXsKtJYVxevxJbL8mNUd45DocTlroIjhc3O8rGuVrnM\nmXYkyUyGxzzHn1dsMzgSobcPWXdevdboii9EhCjxhYgQJb4QEaLEFyJClPhCRIgSX4gIaYuct3NX\n6+KYc3Ncotha5dJbV5G7ps69x+eIO338DRqbnOEOpzFHertUnqKxaoMX8Lw2PkFj3Ru5W25gM3cR\nDu/kcl6+xCW7mlNUMp125DVn3rl8nkt91QqX0BJP7gpc7qo7++C5CGdnueRad1x9niznufM8FyGM\np2Mux/viNEfRFV+ICFHiCxEhSnwhIkSJL0SEKPGFiJA7Jr6Z5c3sJTN7xcxOmtlTzeX9ZnbEzF4z\nsx+ZGXdlCCHWFcuZO69iZr8bQpg3szSAF8zsfwP4QwDPhxC+bGZPAvgigC+02sbWnbtabrtW45Jd\npcLltdnJ6zR25u1zNHb2wlUay+W4e+3nR4/TWE83l63yJV5YsdC1icZ2OZLdyFY+N2DKmV/NK9ZY\nclxvlnJkK6doZuJcU+pOfcuM49zLOM5LZ9o51Gp8H4qOM9Ebz3TaK8TJKS/w+SKdQ+T20zu2jGV9\n1Q8h3JiNMY/FD4sA4AkAh5vLDwP46F23LoToCMtKfDNLNafIHgXwXAjhKIDhEMIYAIQQRgEMrV03\nhRCrybKe3AuLlQUeMbMeAN83swP41S9X9MvW33/3ezdf739oPw48tP8euiqEWC3u6pHdEMK0mf0U\nwOMAxsxsOIQwZmYjAK6w9f7zJ//TynophFhVlnNXf9ONO/ZmVgTwYQBnADwL4NPNt30KwDNr1Ech\nxCqznCv+ZgCHzSyFxQ+K/xlC+IGZvQjg78zsjwGcB8AL0wkh1hUWvLnDVqMBs3Dkhedbxjw5z5VL\nEr7e3Nw8jc3P87nlco5rquQ4zVxnVJrLLMGRihD453GxyGXHTMqZz83Ru8z53pcYXy/tFJys1Rxn\nm6PnNRxHXKnIZceuLj4u8/PcgZdy5ilMZZyioHXuMAzOWHuOv5kZ3k+vuCfLlcd/598iEEujntwT\nIkKU+EJEiBJfiAhR4gsRIUp8ISJEiS9EhLRFzlvTBoQQFCbnrXniCyHWH/qqL0SEKPGFiBAlvhAR\nosQXIkKU+EJEyL8AMSVCLPeeNRIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2401e800c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show random image     \n",
    "x = np.random.random_integers(0, high=num_images)\n",
    "show(img[x,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">2</div> **Comment on the distribution of class labels and the dimentionality of the input and how these may affect the analyses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21080068cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the prior\n",
    "prior = compute_prior(lbl)\n",
    "print('prior:',prior)\n",
    "\n",
    "# plot histogram\n",
    "plt.hist(lbl, bins=10, normed=True, color='salmon')\n",
    "plt.title('Histogram CIFAR10 dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "According to the histogram above the distribution of class labels is exactly uniform. The prior distribution will not have any affect to the analysis.   \n",
    "The dimentionality of input is 32 x 32 x 3 = 1024 x 3. Data is 1024x3 dimensional matrix of values from 0 to 1. The dimentionality is high, we can suggest a way to reduce it. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">3</div> **Classification**  \n",
    "\n",
    "**a) Implement the  `Naive Bayes classifier` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the mean and std of each pixel for each channel for each class for given image\n",
    "def compute_mean_and_std_2(images):\n",
    "    # reshape images\n",
    "    img_ = images.reshape((num_images,img_size*img_size,num_channels))\n",
    "    mean = []\n",
    "    std = []\n",
    "    for k in range(num_classes):\n",
    "        # chose images that belongs to class k\n",
    "        indices = np.argwhere(lbl == k)[:,0]\n",
    "        img_class = img_[indices,:]\n",
    "        mean_class = []\n",
    "        std_class = []\n",
    "        # compute mean and std for each channel for given class\n",
    "        for i in range(num_channels):\n",
    "            mean_class.append(np.mean(img_class[:,:,i], axis=0))\n",
    "            std_class.append(np.std(img_class[:,:,i], axis=0))\n",
    "        mean.append(mean_class)\n",
    "        std.append(std_class)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# compute Gaussian loglikelihood for given image and class for each channel\n",
    "def compute_log_likelihood_3(image, k):\n",
    "    llh = 0\n",
    "    for x in range(num_channels):  \n",
    "        llh_channel = 0\n",
    "        indices = np.argwhere(std[k][x][:] != 0)[:,0]\n",
    "        std_im = std[k][x][indices]\n",
    "        mean_im = mean[k][x][indices]\n",
    "        image_im = image[indices,x]\n",
    "        llh_channel = (-np.log(std_im)-np.log(np.sqrt(2*math.pi))-((image_im-mean_im)**2/(2*std_im**2))).sum()\n",
    "        llh = llh + llh_channel\n",
    "    return llh\n",
    "\n",
    "\n",
    "# make predictions\n",
    "def predict_3(images, labels):\n",
    "    count = 0\n",
    "    N = len(images)\n",
    "    images_ = images.reshape((N,img_size*img_size,num_channels))\n",
    "    predictions = np.array([], int)\n",
    "    # compute posterior for each image\n",
    "    for i in range(N):\n",
    "        posterior = [compute_log_likelihood_3(images_[i,:,:], k) * prior[k] for k in range(num_classes)]\n",
    "        pred = posterior.index(max(posterior))\n",
    "        predictions = np.append(predictions, pred)\n",
    "        if pred == labels[i]:\n",
    "            count += 1\n",
    "    accuracy = count/N\n",
    "    return predictions, accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test takes 0.512267 minutes\n",
      "The accuracy =  0.2976\n"
     ]
    }
   ],
   "source": [
    "mean, std = compute_mean_and_std_2(img)\n",
    "\n",
    "t0 = time()\n",
    "predictions, accuracy = predict_3(img_test,lbl_test)\n",
    "t1 = time()\n",
    "\n",
    "print('The test takes %f minutes' %((t1-t0)/60))\n",
    "print('The accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.2976\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**—Å) Describe any data pre-processing that you suggest for this data and your classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Because the dimensionality is very high we should find a way to reduce it. The simplest one can be averaging the values of these three RGB channels or we can apply PCA.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Apply your classifier to the dataset. Make sure your optimization is clearly commented. Use classification accuracy and test log-likelihood as your figures of merit.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = img.reshape(50000, 32*32*3)\n",
    "img_test = img_test.reshape(10000, 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start at: 09:40:13\n",
      "Building the model takes 4.677074 minutes\n",
      "Applying the dimensionality reduction takes 1.871455 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('The start at:', strftime(\"%H:%M:%S\"))\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components=80)\n",
    "pca.fit(img)\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "img_opt = pca.transform(img)\n",
    "img_test_opt = pca.transform(img_test)\n",
    "\n",
    "t2 = time()\n",
    "print('Building the model takes %f minutes' %((t1-t0)/60)) \n",
    "print('Applying the dimensionality reduction takes %f minutes' %((t2-t1)/60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test takes 0.101828 minutes\n",
      "The accuracy =  0.3442\n"
     ]
    }
   ],
   "source": [
    "# compute mean and std for obtained images\n",
    "mean, std = compute_mean_and_std(img_opt)\n",
    "\n",
    "# make predictions and compute the accuracy\n",
    "t0 = time()\n",
    "predictions, accuracy = predict(img_test_opt,lbl_test)\n",
    "t1 = time()\n",
    "\n",
    "print('The test takes %f minutes' %((t1-t0)/60)) \n",
    "print('The accuracy = ',accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.3442\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Display the confusion matrix on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  240   49   44   36   29   23   13   41   75   61\n",
      "1   79  428   40   59   21   52   38   55  104  160\n",
      "2   36   20  100   67   69   81   39   41   20   11\n",
      "3   43   43   75  217   42  130   56   63   30   51\n",
      "4  243   51  423  183  597  193  332  181  175   49\n",
      "5   26   28   75  130   39  260   55   74   30   18\n",
      "6   31   34   89  104   84   72  368   48   33   36\n",
      "7   43   37   53   63   68   74   29  339   22   36\n",
      "8  167  123   38   25   28   26   14   31  431  116\n",
      "9   92  187   63  116   23   89   56  127   80  462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(predictions, lbl_test)\n",
    "\n",
    "# display confusion matrix: actual values are presented by rows, predicted by columns\n",
    "print('Confusion matrix:\\n')\n",
    "print(pd.DataFrame(conf_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Discuss the performance, compare them against a classifier that outputs random class labels and suggest in which performance could be improved.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The classifier that outputs random class labels will provide the accuracy about 0.10, and we obtained about 0.34. It's better but still very low. To get better result we should take into account the —Åorrelation between pixels by assuming multivariate normal distribution and applying the `Bayes classifier`.   \n",
    "Moreover we can use `Convolutional Neural Networks` to perform this classification task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"label label-success\">4</div> **Linear Regression**\n",
    "\n",
    "**a) Implement `Bayesian linear regression`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add bias to train dataset\n",
    "X = np.append(img,np.ones((num_images,1)),axis=1)\n",
    "t = lbl\n",
    "\n",
    "# compute w_hat and sigma2_hat (by maximizing likelihood)\n",
    "w_hat = np.dot(np.dot(pinv(np.dot(X.T,X)),X.T),t)\n",
    "sigma2_hat = np.dot((t - np.dot(X,w_hat)).T,(t - np.dot(X,w_hat)))/num_images\n",
    "\n",
    "# add bias to test dataset\n",
    "X_new = np.append(img_test,np.ones((num_images_test,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean of the prior\n",
    "O = np.zeros((32*32*3+1,1)); \n",
    "# covariance of the prior\n",
    "S = 10 * np.identity(32*32*3+1) \n",
    "\n",
    "# compute the covariance of the posterior\n",
    "SIGMA = inv(1/sigma2_hat*np.dot(X.T,X) + inv(S))\n",
    "# compute the mean of the posterior\n",
    "MU = 1/sigma2_hat*np.dot(np.dot(SIGMA,X.T),t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Treat class labels as continuous and apply regression to the training data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Produce a scatter plot showing the prediction versus the true targets for the test set and compute the mean squared error on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the results with MU as parameters of the model and predictions as continuous values \n",
    "predictions = predict_continuous(X_new,lbl_test,MU)\n",
    "\n",
    "# compute error for all points\n",
    "error = predictions - lbl_test\n",
    "print('mean of error:',np.mean(error),'\\nstd of error:',np.std(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the test set: 7.8779\n"
     ]
    }
   ],
   "source": [
    "# the mean squared error on the test set\n",
    "MSE = compute_mse(predictions, lbl_test)\n",
    "print('MSE on the test set:',round(MSE,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Suggest a way to discretize predictions and display the confusion matrix on the test data and report accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy = 0.1131\n"
     ]
    }
   ],
   "source": [
    "# get the results with the best value for the modl = MU and predictions as discrete values\n",
    "predictions, accuracy = predict_discrete(X_new, lbl_test, MU)\n",
    "print('\\nThe accuracy =',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The accuracy = 0.1131\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "The obtained accuracy is equivalent to the accuracy that we will get with classifier that outputs random class variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "    0    1    2    3    4    5    6    7    8    9    10  11\n",
      "0    0    0    0    0    1    0    0    0    0    0    1   0\n",
      "1    0    0    0    0    1    0    1    0    0    0    0   0\n",
      "2    0    5   10    2    5    2    2    0    2    1    2   0\n",
      "3    0   31   40   24   37   18   33   11   10    9    7   0\n",
      "4    0  236  155  157  162  143  167  107   93   60   71   0\n",
      "5    0  411  353  430  394  411  383  328  299  321  195   0\n",
      "6    0  226  275  304  298  331  311  392  322  408  348   0\n",
      "7    0   75  119   66   89   78   89  134  187  158  260   0\n",
      "8    0   12   35   12   10   16   13   22   67   36   88   0\n",
      "9    0    2   10    4    3    1    1    6   15    7   20   0\n",
      "10   0    2    3    1    0    0    0    0    5    0    5   0\n",
      "11   0    0    0    0    0    0    0    0    0    0    3   0\n"
     ]
    }
   ],
   "source": [
    "# display confusion matrix: actual values are presented by rows, predicted by columns\n",
    "conf_matrix = confusion_matrix(predictions, lbl_test)\n",
    "\n",
    "print('Confusion matrix:\\n')\n",
    "print(pd.DataFrame(conf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Discuss regression performance with respect to classification performance**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Given above for the MNIST dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Describe one limitation of using regression for this particular task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Given above for the MNIST dataset.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
